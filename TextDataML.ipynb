{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Data Processing and Classification\n",
        "## 20newsgroups data used"
      ],
      "metadata": {
        "id": "H_Dp3bDAiCro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is called “Twenty Newsgroups”. Here is the official description, quoted from the website:\n",
        "\n",
        "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. "
      ],
      "metadata": {
        "id": "PU915GZUiazP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get faster execution times for this first example, we will work on a partial dataset with only **4 categories out of the 20 available** in the dataset:"
      ],
      "metadata": {
        "id": "p7eaAFAXi4qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "   'comp.graphics', 'sci.med']"
      ],
      "metadata": {
        "id": "L2E8jc2DdZVv"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading: 20newsgroups"
      ],
      "metadata": {
        "id": "ghOC_M26lPSo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KgZgFT9QdKze"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKChvZ_xdjd5",
        "outputId": "2f37239b-ddbc-4f9b-86ad-f34e1eb5025e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLvlTenqdu1p",
        "outputId": "840f2a31-95d1-4fc1-d3b2-bfbd66c9019b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train.filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdo8SH4Udxrf",
        "outputId": "2b5c575f-8925-4de4-a309-6dce41f2bb1c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj4xvOesd1M2",
        "outputId": "f0947e49-25c7-44c3-cadc-ac72b8e7a4f4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: sd345@city.ac.uk (Michael Collier)\n",
            "Subject: Converting images to HP LaserJet III?\n",
            "Nntp-Posting-Host: hampton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(twenty_train.target_names[twenty_train.target[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIaR5cphd_eJ",
        "outputId": "9065f0a9-85e7-4fc1-9c9f-8c4fcc712e0a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXFZ_9IeCHQ",
        "outputId": "d4cb8836-1d1c-4e4f-9f9f-ad0915c07aac"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in twenty_train.target[:10]:\n",
        "  print(twenty_train.target_names[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFpJYd6heGu3",
        "outputId": "f1acaa9f-5618-47a4-9a97-c9fdf228f088"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n",
            "comp.graphics\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting features from text files\n",
        "\n",
        "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.\n",
        "\n",
        "### Bags of words\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fr_ZBt2MeN0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXBI0V0GfCU2",
        "outputId": "1bf12fd0-3a63-4310-f2cb-734a0f18a1b1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect.vocabulary_.get(u'algorithm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IE_N0bqfOq-",
        "outputId": "b8797c8e-079a-430d-b50a-f45d0d0e0d50"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text data scaling and normalization\n",
        "# From occurrences to frequencies\n",
        "\n",
        "these new features are called tf for Term Frequencies.\n",
        "\n",
        "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”.\n",
        "\n",
        "Both tf and tf–idf can be computed as follows using TfidfTransformer:"
      ],
      "metadata": {
        "id": "4FU3qTZlgCNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affldWlugnNF",
        "outputId": "07dd89a5-6324-4fe9-931b-b87d2308e64a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a classifier: Naive Bayes\n"
      ],
      "metadata": {
        "id": "8PM182jJgwSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "x4n8WrHrg0Al"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "  print('%r => %s' % (doc, twenty_train.target_names[category]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJTzclYQg6FK",
        "outputId": "38ca7726-cbad-4f19-fe41-80096d3800b0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => soc.religion.christian\n",
            "'OpenGL on the GPU is fast' => comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building end to end a pipeline\n"
      ],
      "metadata": {
        "id": "02pJqSZGhS79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB()),])"
      ],
      "metadata": {
        "id": "1jak32iDhV_w"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "Pipeline(...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bqwEVxclhaVh",
        "outputId": "28e6c0bf-b7d6-4f4d-f446-ce4d7198ea97"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=Ellipsis)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=Ellipsis)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=Ellipsis)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', \n",
        "categories=categories, shuffle=True, random_state=42)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDfbAtkHhdMA",
        "outputId": "8903d603-2fd2-42c2-9631-cac26633c289"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348868175765646"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved 83.5% accuracy. Let’s see if we can do better with a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:"
      ],
      "metadata": {
        "id": "KVQzU2SshmXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use SVM for Same Data"
      ],
      "metadata": {
        "id": "MTIe-9-Klcik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf = Pipeline([\n",
        "     ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                           alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "                      ])\n",
        "\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "Pipeline(...)\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH3I5HPfhpF0",
        "outputId": "9de2bea4-6d6d-457f-f5b8-a51a41d28ba2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9101198402130493"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved 91.3% accuracy using the SVM. scikit-learn provides further utilities for more detailed performance analysis of the results:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hsFGvZfKht9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show evaluation Parameters"
      ],
      "metadata": {
        "id": "EZYDumMtlji-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(twenty_test.target, predicted,\n",
        "     target_names=twenty_test.target_names))\n",
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-w5jTnEhzJk",
        "outputId": "217d6f18-9949-4b88-8152-fbd7d86e579b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.95      0.80      0.87       319\n",
            "         comp.graphics       0.87      0.98      0.92       389\n",
            "               sci.med       0.94      0.89      0.91       396\n",
            "soc.religion.christian       0.90      0.95      0.93       398\n",
            "\n",
            "              accuracy                           0.91      1502\n",
            "             macro avg       0.91      0.91      0.91      1502\n",
            "          weighted avg       0.91      0.91      0.91      1502\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[256,  11,  16,  36],\n",
              "       [  4, 380,   3,   2],\n",
              "       [  5,  35, 353,   3],\n",
              "       [  5,  11,   4, 378]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Tunning Using Grid Cross Validation"
      ],
      "metadata": {
        "id": "N0Rsr6gQln4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\n",
        "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "     'tfidf__use_idf': (True, False),\n",
        "     'clf__alpha': (1e-2, 1e-3),\n",
        " }"
      ],
      "metadata": {
        "id": "fwunuhJMh15B"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n"
      ],
      "metadata": {
        "id": "T1O0mGsNh5Ow"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])\n"
      ],
      "metadata": {
        "id": "ER5r8wGdh6oH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SiYMEG1fh8CY",
        "outputId": "132aaed2-92eb-4d9f-bd29-79fb41516f16"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'soc.religion.christian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf.best_score_\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS5S1iESh-dN",
        "outputId": "ca9bd035-41c9-44d8-9038-115d3deb8e04"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9175000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param_name in sorted(parameters.keys()):\n",
        "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzmhWqwCkU4K",
        "outputId": "f66a3563-0a74-4f19-b095-c0ca649971c3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clf__alpha: 0.001\n",
            "tfidf__use_idf: True\n",
            "vect__ngram_range: (1, 1)\n"
          ]
        }
      ]
    }
  ]
}